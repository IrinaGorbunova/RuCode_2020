# Fake News classicifation

Имеются тексты новостей, требуется определить является ли новость настоящей или нет.

Для решения данной задачи я использовала предобученные модели трансформеров из библиотеки **Hugging Face**: **XLM-RoBERTa** и **BERT**.

Так как тексты на русском, то целесообразно было использовать модели, обученные на русском языке или на нескольких языках, включая русский.

Результаты по каждой рассмотренной модели представлены в таблице:

| Model | Parameters | Language | Best mean F1 (val) | Best mean F1 (test) | 
|:-------:|:-------:|:-------:|:-------:|:----------:|
| **xlm-roberta-large**      | 355M | 100 languages | 1.000 | **1.000** |
| xlm-roberta-base      | 125M | 100 languages | 0.998 | - |
| bert-base-multilingual-cased      | 110M | 104 languages | 0.985 | - |
| DeepPavlov/rubert-base-cased      | 110M | russian | 0.989 | - |
| DrMatters/rubert_cased      | 110M | russian | 0.989 | - |

Для обучения каждой модели использовались одни и те же параметры:

LR = 5e-5 \
Batch size = 8 \
Max len = 256 (максимальная длина входной последовательности)

Обучение продолжалось 10 эпох, после чего выбирался лучший результат.

Эксперименты показали, что XLM-RoBERTa справляется с данной задачей лучше, чем BERT.
А русскоязычные модели лучше, чем многоязычные.
